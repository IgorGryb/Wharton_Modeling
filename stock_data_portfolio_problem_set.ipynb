{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Portfolio Optimization Problem Set (Step 3)\n",
        "\n",
        "This notebook follows the course instructions for Step 3 using adjusted close daily returns.\n",
        "- Step 3.1: 5% grid search for the minimum-variance WFC/MSFT portfolio.\n",
        "- Step 3.2: Exact minimum-variance weights and the tangency (optimal risky) portfolio for WFC/MSFT.\n",
        "- Step 3.3: Tangency portfolios using all 10 stocks (unconstrained and long-only).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "from datetime import datetime\n",
        "from math import sqrt\n",
        "from pathlib import Path\n",
        "\n",
        "DATA_DIR = Path('Historical Stock Data')\n",
        "PATHS = {\n",
        "    'AAPL': DATA_DIR / '_c6159646c4566d0145fba7a91f251330_aapl.csv',\n",
        "    'MSFT': DATA_DIR / '_c6159646c4566d0145fba7a91f251330_msft.csv',\n",
        "    'WFC': DATA_DIR / '_d54e93ebdf2971e11509d23595ca6209_wfc.csv',\n",
        "    'DIS': DATA_DIR / '_c6159646c4566d0145fba7a91f251330_dis.csv',\n",
        "    'COP': DATA_DIR / '_c6159646c4566d0145fba7a91f251330_cop.csv',\n",
        "    'XOM': DATA_DIR / '_d54e93ebdf2971e11509d23595ca6209_xom.csv',\n",
        "    'GOOG': DATA_DIR / '_c6159646c4566d0145fba7a91f251330_goog.csv',\n",
        "    'BIDU': DATA_DIR / '_c6159646c4566d0145fba7a91f251330_bidu.csv',\n",
        "    'TSLA': DATA_DIR / '_d54e93ebdf2971e11509d23595ca6209_tsla.csv',\n",
        "    'TTM': DATA_DIR / '_d54e93ebdf2971e11509d23595ca6209_ttm.csv',\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_date(value):\n",
        "    return datetime.strptime(value, '%m/%d/%y').date()\n",
        "\n",
        "def load_adj_close(path):\n",
        "    rows = []\n",
        "    with path.open(newline='') as handle:\n",
        "        reader = csv.DictReader(handle)\n",
        "        for row in reader:\n",
        "            rows.append({\n",
        "                'date': parse_date(row['Date']),\n",
        "                'adj_close': float(row['Adj Close']),\n",
        "            })\n",
        "    rows.sort(key=lambda item: item['date'])\n",
        "    return rows\n",
        "\n",
        "def returns_by_date(rows):\n",
        "    returns = {}\n",
        "    previous = None\n",
        "    for row in rows:\n",
        "        if previous is not None:\n",
        "            returns[row['date']] = (row['adj_close'] - previous['adj_close']) / previous['adj_close'] * 100.0\n",
        "        previous = row\n",
        "    return returns\n",
        "\n",
        "def align_returns(symbols, paths):\n",
        "    returns_map = {sym: returns_by_date(load_adj_close(paths[sym])) for sym in symbols}\n",
        "    common_dates = None\n",
        "    for sym in symbols:\n",
        "        dates = set(returns_map[sym].keys())\n",
        "        common_dates = dates if common_dates is None else common_dates & dates\n",
        "    dates_sorted = sorted(common_dates)\n",
        "    aligned = {sym: [returns_map[sym][d] for d in dates_sorted] for sym in symbols}\n",
        "    return aligned\n",
        "\n",
        "def mean(values):\n",
        "    return sum(values) / len(values)\n",
        "\n",
        "def covariance(x, y):\n",
        "    n = len(x)\n",
        "    mx = mean(x)\n",
        "    my = mean(y)\n",
        "    return sum((xi - mx) * (yi - my) for xi, yi in zip(x, y)) / (n - 1)\n",
        "\n",
        "def covariance_matrix(returns_by_asset, symbols):\n",
        "    return [[covariance(returns_by_asset[a], returns_by_asset[b]) for b in symbols] for a in symbols]\n",
        "\n",
        "def dot(a, b):\n",
        "    return sum(x * y for x, y in zip(a, b))\n",
        "\n",
        "def matvec(mat, vec):\n",
        "    return [dot(row, vec) for row in mat]\n",
        "\n",
        "def portfolio_stats(weights, mean_returns, cov):\n",
        "    port_mean = dot(mean_returns, weights)\n",
        "    var = dot(weights, matvec(cov, weights))\n",
        "    std = sqrt(var)\n",
        "    sharpe = port_mean / std\n",
        "    return port_mean, std, sharpe\n",
        "\n",
        "def min_variance_weight_two_asset(cov):\n",
        "    var1 = cov[0][0]\n",
        "    var2 = cov[1][1]\n",
        "    cov12 = cov[0][1]\n",
        "    w1 = (var2 - cov12) / (var1 + var2 - 2 * cov12)\n",
        "    return w1, 1 - w1\n",
        "\n",
        "def invert_matrix(matrix):\n",
        "    n = len(matrix)\n",
        "    mat = [row[:] + [0.0] * n for row in matrix]\n",
        "    for i in range(n):\n",
        "        mat[i][n + i] = 1.0\n",
        "    for i in range(n):\n",
        "        pivot = mat[i][i]\n",
        "        if abs(pivot) < 1e-12:\n",
        "            for r in range(i + 1, n):\n",
        "                if abs(mat[r][i]) > abs(pivot):\n",
        "                    mat[i], mat[r] = mat[r], mat[i]\n",
        "                    pivot = mat[i][i]\n",
        "                    break\n",
        "        if abs(pivot) < 1e-12:\n",
        "            raise ValueError('Singular matrix')\n",
        "        scale = 1.0 / pivot\n",
        "        mat[i] = [v * scale for v in mat[i]]\n",
        "        for r in range(n):\n",
        "            if r == i:\n",
        "                continue\n",
        "            factor = mat[r][i]\n",
        "            if factor != 0.0:\n",
        "                mat[r] = [rv - factor * iv for rv, iv in zip(mat[r], mat[i])]\n",
        "    return [row[n:] for row in mat]\n",
        "\n",
        "def tangency_weights_unconstrained(mean_returns, cov):\n",
        "    inv = invert_matrix(cov)\n",
        "    raw = matvec(inv, mean_returns)\n",
        "    total = sum(raw)\n",
        "    return [v / total for v in raw]\n",
        "\n",
        "def project_to_simplex(vector):\n",
        "    sorted_v = sorted(vector, reverse=True)\n",
        "    cumsum = 0.0\n",
        "    rho = -1\n",
        "    for i, val in enumerate(sorted_v):\n",
        "        cumsum += val\n",
        "        t = (cumsum - 1.0) / (i + 1)\n",
        "        if val - t > 0:\n",
        "            rho = i\n",
        "    if rho == -1:\n",
        "        return [1.0 / len(vector)] * len(vector)\n",
        "    theta = (sum(sorted_v[:rho + 1]) - 1.0) / (rho + 1)\n",
        "    return [max(v - theta, 0.0) for v in vector]\n",
        "\n",
        "def sharpe_ratio(weights, mean_returns, cov):\n",
        "    mu = dot(mean_returns, weights)\n",
        "    var = dot(weights, matvec(cov, weights))\n",
        "    if var <= 0:\n",
        "        return -1e18\n",
        "    return mu / sqrt(var)\n",
        "\n",
        "def gradient(weights, mean_returns, cov):\n",
        "    mu = dot(mean_returns, weights)\n",
        "    v = dot(weights, matvec(cov, weights))\n",
        "    if v <= 0:\n",
        "        return [0.0] * len(weights)\n",
        "    sigma_w = matvec(cov, weights)\n",
        "    denom = v ** 1.5\n",
        "    return [((m * v) - (mu * sw)) / denom for m, sw in zip(mean_returns, sigma_w)]\n",
        "\n",
        "def maximize_sharpe_long_only(mean_returns, cov, max_iter=5000):\n",
        "    weights = [1.0 / len(mean_returns)] * len(mean_returns)\n",
        "    current = sharpe_ratio(weights, mean_returns, cov)\n",
        "    steps = [1.0, 0.5, 0.1, 0.05, 0.01, 0.005, 0.001]\n",
        "    for _ in range(max_iter):\n",
        "        grad = gradient(weights, mean_returns, cov)\n",
        "        best = current\n",
        "        best_w = weights\n",
        "        improved = False\n",
        "        for step in steps:\n",
        "            candidate = project_to_simplex([w + step * g for w, g in zip(weights, grad)])\n",
        "            score = sharpe_ratio(candidate, mean_returns, cov)\n",
        "            if score > best + 1e-12:\n",
        "                best = score\n",
        "                best_w = candidate\n",
        "                improved = True\n",
        "        weights = best_w\n",
        "        current = best\n",
        "        if not improved:\n",
        "            break\n",
        "    return weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3.1 and 3.2: WFC/MSFT minimum-variance portfolio\n",
        "two_symbols = ['WFC', 'MSFT']\n",
        "two_returns = align_returns(two_symbols, PATHS)\n",
        "two_means = [mean(two_returns[s]) for s in two_symbols]\n",
        "two_cov = covariance_matrix(two_returns, two_symbols)\n",
        "\n",
        "best_std = None\n",
        "best_weights = None\n",
        "for i in range(0, 101, 5):\n",
        "    w_wfc = i / 100.0\n",
        "    w_msft = 1 - w_wfc\n",
        "    _, std, _ = portfolio_stats([w_wfc, w_msft], two_means, two_cov)\n",
        "    if best_std is None or std < best_std:\n",
        "        best_std = std\n",
        "        best_weights = (w_wfc, w_msft)\n",
        "\n",
        "minvar_wfc, minvar_msft = min_variance_weight_two_asset(two_cov)\n",
        "\n",
        "# Step 3.2: WFC/MSFT optimal risky portfolio (max Sharpe, rf = 0)\n",
        "tan_two = tangency_weights_unconstrained(two_means, two_cov)\n",
        "tan_two_stats = portfolio_stats(tan_two, two_means, two_cov)\n",
        "\n",
        "wfc_sharpe = two_means[0] / sqrt(two_cov[0][0])\n",
        "msft_sharpe = two_means[1] / sqrt(two_cov[1][1])\n",
        "\n",
        "# Step 3.3: Tangency portfolios using all 10 securities (no DJI)\n",
        "all_symbols = ['AAPL', 'MSFT', 'WFC', 'DIS', 'COP', 'XOM', 'GOOG', 'BIDU', 'TSLA', 'TTM']\n",
        "all_returns = align_returns(all_symbols, PATHS)\n",
        "all_means = [mean(all_returns[s]) for s in all_symbols]\n",
        "all_cov = covariance_matrix(all_returns, all_symbols)\n",
        "\n",
        "tan_unconstrained = tangency_weights_unconstrained(all_means, all_cov)\n",
        "uncon_stats = portfolio_stats(tan_unconstrained, all_means, all_cov)\n",
        "\n",
        "tan_long_only = maximize_sharpe_long_only(all_means, all_cov)\n",
        "long_stats = portfolio_stats(tan_long_only, all_means, all_cov)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3.1 (Grid, 5%): WFC 45%, MSFT 55%\n",
            "Step 3.2 (Min-Var Formula): WFC 44.7%, MSFT 55.3%\n",
            "Step 3.2 (Tangency WFC/MSFT): WFC 31.9%\n",
            "Sharpe Ratios - WFC 0.040, MSFT 0.050, Portfolio 0.053\n",
            "Unconstrained Tangency (10-asset) Weights:\n",
            "  AAPL: 20.7%\n",
            "  MSFT: 15.2%\n",
            "  WFC: -17.4%\n",
            "  DIS: 49.7%\n",
            "  COP: -24.6%\n",
            "  XOM: 22.0%\n",
            "  GOOG: 20.1%\n",
            "  BIDU: -1.5%\n",
            "  TSLA: 17.9%\n",
            "  TTM: -2.1%\n",
            "Unconstrained Mean 0.11%, Std 1.30%, Sharpe 0.088\n",
            "Long-Only Tangency (10-asset) Weights:\n",
            "  AAPL: 17.1%\n",
            "  MSFT: 9.9%\n",
            "  WFC: 0.0%\n",
            "  DIS: 38.8%\n",
            "  COP: 0.0%\n",
            "  XOM: 0.0%\n",
            "  GOOG: 17.5%\n",
            "  BIDU: 0.0%\n",
            "  TSLA: 16.7%\n",
            "  TTM: 0.0%\n",
            "Long-Only Mean 0.11%, Std 1.26%, Sharpe 0.084\n"
          ]
        }
      ],
      "source": [
        "print('Step 3.1 (Grid, 5%): WFC {:.0f}%, MSFT {:.0f}%'.format(best_weights[0] * 100, best_weights[1] * 100))\n",
        "print('Step 3.2 (Min-Var Formula): WFC {:.1f}%, MSFT {:.1f}%'.format(minvar_wfc * 100, minvar_msft * 100))\n",
        "print('Step 3.2 (Tangency WFC/MSFT): WFC {:.1f}%'.format(tan_two[0] * 100))\n",
        "print('Sharpe Ratios - WFC {:.3f}, MSFT {:.3f}, Portfolio {:.3f}'.format(wfc_sharpe, msft_sharpe, tan_two_stats[2]))\n",
        "\n",
        "print('Unconstrained Tangency (10-asset) Weights:')\n",
        "for sym, w in zip(all_symbols, tan_unconstrained):\n",
        "    print('  {}: {:.1f}%'.format(sym, w * 100))\n",
        "print('Unconstrained Mean {:.2f}%, Std {:.2f}%, Sharpe {:.3f}'.format(uncon_stats[0], uncon_stats[1], uncon_stats[2]))\n",
        "\n",
        "print('Long-Only Tangency (10-asset) Weights:')\n",
        "for sym, w in zip(all_symbols, tan_long_only):\n",
        "    print('  {}: {:.1f}%'.format(sym, w * 100))\n",
        "print('Long-Only Mean {:.2f}%, Std {:.2f}%, Sharpe {:.3f}'.format(long_stats[0], long_stats[1], long_stats[2]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final Answers\n",
        "\n",
        "1. 45%; 55%\n",
        "2. 44.7%; 55.3%\n",
        "3. 31.9\n",
        "4. The optimal risky portfolio displays a higher Sharpe Ratio than either of the two stocks used in the portfolio.\n",
        "5. 22.0\n",
        "6. 17.5\n",
        "7. 0.11\n",
        "8. 1.26\n",
        "9. 0.088\n",
        "10. When short selling is allowed, the portfolio is able to attain a higher level of Sharpe Ratio.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
